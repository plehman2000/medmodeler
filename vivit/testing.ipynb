{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json not found in HuggingFace Hub\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "753b3bb1b70b45ccb1ac873ab8b8ae0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OpError",
     "evalue": "file is too short to be an sstable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOpError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32me:\\Projects\\Lab\\MRI\\pablo\\testing.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Projects/Lab/MRI/pablo/testing.ipynb#W0sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     model\u001b[39m.\u001b[39mcompile(\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Projects/Lab/MRI/pablo/testing.ipynb#W0sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         optimizer\u001b[39m=\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39mLEARNING_RATE),\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Projects/Lab/MRI/pablo/testing.ipynb#W0sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Projects/Lab/MRI/pablo/testing.ipynb#W0sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m         \u001b[39m# ],\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Projects/Lab/MRI/pablo/testing.ipynb#W0sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Projects/Lab/MRI/pablo/testing.ipynb#W0sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Projects/Lab/MRI/pablo/testing.ipynb#W0sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m model \u001b[39m=\u001b[39m get_model()\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Projects/Lab/MRI/pablo/testing.ipynb#W0sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m labels \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mliver\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mkidney-right\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mkidney-left\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfemur-right\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfemur-left\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbladder\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mheart\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlung-right\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlung-left\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mspleen\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpancreas\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Projects/Lab/MRI/pablo/testing.ipynb#W0sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_label\u001b[39m(path):\n",
      "\u001b[1;32me:\\Projects\\Lab\\MRI\\pablo\\testing.ipynb Cell 1\u001b[0m in \u001b[0;36mget_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Projects/Lab/MRI/pablo/testing.ipynb#W0sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_model\u001b[39m():\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Projects/Lab/MRI/pablo/testing.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Projects/Lab/MRI/pablo/testing.ipynb#W0sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m    Download the model from the Hugging Face Hub and compile it.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Projects/Lab/MRI/pablo/testing.ipynb#W0sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Projects/Lab/MRI/pablo/testing.ipynb#W0sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     model \u001b[39m=\u001b[39m from_pretrained_keras(\u001b[39m\"\u001b[39;49m\u001b[39mpablorodriper/video-vision-transformer\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Projects/Lab/MRI/pablo/testing.ipynb#W0sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     model\u001b[39m.\u001b[39mcompile(\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Projects/Lab/MRI/pablo/testing.ipynb#W0sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         optimizer\u001b[39m=\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39mLEARNING_RATE),\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Projects/Lab/MRI/pablo/testing.ipynb#W0sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Projects/Lab/MRI/pablo/testing.ipynb#W0sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m         \u001b[39m# ],\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Projects/Lab/MRI/pablo/testing.ipynb#W0sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Projects/Lab/MRI/pablo/testing.ipynb#W0sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32me:\\Applications\\Anaconda\\envs\\new\\lib\\site-packages\\huggingface_hub\\keras_mixin.py:284\u001b[0m, in \u001b[0;36mfrom_pretrained_keras\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_pretrained_keras\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    229\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[39m    Instantiate a pretrained Keras model from a pre-trained model from the Hub.\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \u001b[39m    The model is expected to be in SavedModel format.```\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[39m    </Tip>\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 284\u001b[0m     \u001b[39mreturn\u001b[39;00m KerasModelHubMixin\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\Applications\\Anaconda\\envs\\new\\lib\\site-packages\\huggingface_hub\\hub_mixin.py:211\u001b[0m, in \u001b[0;36mModelHubMixin.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, force_download, resume_download, proxies, use_auth_token, cache_dir, local_files_only, **model_kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m         config \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n\u001b[0;32m    209\u001b[0m     model_kwargs\u001b[39m.\u001b[39mupdate({\u001b[39m\"\u001b[39m\u001b[39mconfig\u001b[39m\u001b[39m\"\u001b[39m: config})\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_from_pretrained(\n\u001b[0;32m    212\u001b[0m     model_id,\n\u001b[0;32m    213\u001b[0m     revision,\n\u001b[0;32m    214\u001b[0m     cache_dir,\n\u001b[0;32m    215\u001b[0m     force_download,\n\u001b[0;32m    216\u001b[0m     proxies,\n\u001b[0;32m    217\u001b[0m     resume_download,\n\u001b[0;32m    218\u001b[0m     local_files_only,\n\u001b[0;32m    219\u001b[0m     use_auth_token,\n\u001b[0;32m    220\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[0;32m    221\u001b[0m )\n",
      "File \u001b[1;32me:\\Applications\\Anaconda\\envs\\new\\lib\\site-packages\\huggingface_hub\\keras_mixin.py:625\u001b[0m, in \u001b[0;36mKerasModelHubMixin._from_pretrained\u001b[1;34m(cls, model_id, revision, cache_dir, force_download, proxies, resume_download, local_files_only, use_auth_token, **model_kwargs)\u001b[0m\n\u001b[0;32m    622\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    623\u001b[0m     storage_folder \u001b[39m=\u001b[39m model_id\n\u001b[1;32m--> 625\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mload_model(storage_folder, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)\n\u001b[0;32m    627\u001b[0m \u001b[39m# For now, we add a new attribute, config, to store the config loaded from the hub/a local dir.\u001b[39;00m\n\u001b[0;32m    628\u001b[0m model\u001b[39m.\u001b[39mconfig \u001b[39m=\u001b[39m cfg\n",
      "File \u001b[1;32me:\\Applications\\Anaconda\\envs\\new\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32me:\\Applications\\Anaconda\\envs\\new\\lib\\site-packages\\tensorflow\\python\\training\\py_checkpoint_reader.py:45\u001b[0m, in \u001b[0;36merror_translator\u001b[1;34m(e)\u001b[0m\n\u001b[0;32m     43\u001b[0m   \u001b[39mraise\u001b[39;00m errors_impl\u001b[39m.\u001b[39mInternalError(\u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, error_message)\n\u001b[0;32m     44\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 45\u001b[0m   \u001b[39mraise\u001b[39;00m errors_impl\u001b[39m.\u001b[39mOpError(\u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, error_message, errors_impl\u001b[39m.\u001b[39mUNKNOWN)\n",
      "\u001b[1;31mOpError\u001b[0m: file is too short to be an sstable"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from huggingface_hub import from_pretrained_keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from constants import LEARNING_RATE\n",
    "\n",
    "def get_model():\n",
    "    \"\"\"\n",
    "    Download the model from the Hugging Face Hub and compile it.\n",
    "    \"\"\"\n",
    "    model = from_pretrained_keras(\"pablorodriper/video-vision-transformer\")\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        # metrics=[\n",
    "        #     keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "        #     keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
    "        # ],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_model()\n",
    "labels = ['liver', 'kidney-right', 'kidney-left', 'femur-right', 'femur-left', 'bladder', 'heart', 'lung-right', 'lung-left', 'spleen', 'pancreas']\n",
    "\n",
    "\n",
    "def predict_label(path):\n",
    "    frames = load_video(path)\n",
    "    dataloader = prepare_dataloader(frames)\n",
    "    prediction = model.predict(dataloader)[0]\n",
    "    label = np.argmax(prediction, axis=0)\n",
    "    label = labels[label]\n",
    "\n",
    "    return label\n",
    "\n",
    "\n",
    "def load_video(path):\n",
    "    \"\"\"\n",
    "    Load video from path and return a list of frames. \n",
    "    The video is converted to grayscale because it is the format expected by the model.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            frames.append(frame)\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return np.array(frames)\n",
    "\n",
    "\n",
    "def prepare_dataloader(video):\n",
    "    video = tf.expand_dims(video, axis=0)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((video, np.array([0])))\n",
    "\n",
    "    dataloader = (\n",
    "        dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .batch(1)\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def preprocess(frames: tf.Tensor, label: tf.Tensor):\n",
    "    \"\"\"Preprocess the frames tensors and parse the labels.\"\"\"\n",
    "    # Preprocess images\n",
    "    frames = tf.image.convert_image_dtype(\n",
    "        frames[\n",
    "            ..., tf.newaxis\n",
    "        ],  # The new axis is to help for further processing with Conv3D layers\n",
    "        tf.float32,\n",
    "    )\n",
    "    # Parse label\n",
    "    label = tf.cast(label, tf.float32)\n",
    "    return frames, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "vidpath"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('new')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c39067fb85dad44b96a991ff273746e02ffde2a07ab0e300120c2298a074d00"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
