{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#   FILTER MRI BY VALUE?\n",
    "\n",
    "import torchvision.transforms as T\n",
    "transform = T.ToPILImage()\n",
    "import PIL\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "samp = np.load(os.getcwd() + \"/DATA/sample/sample0.npy\")\n",
    "label = np.load(os.getcwd() + \"/DATA/label/label0.npy\")\n",
    "SLICE_START = 0\n",
    "SLICE_LENGTH = 64\n",
    "sample = torch.tensor(samp)\n",
    "\n",
    "label = torch.tensor(label)\n",
    "sample = torch.narrow(sample, 3, SLICE_START, SLICE_LENGTH)\n",
    "label = torch.narrow(label, 3, SLICE_START, SLICE_LENGTH)\n",
    "lab0 = torch.where(label==0,1,0);lab1 = torch.where(label==1,1,0)\n",
    "lab2 = torch.where(label==2,1,0);lab3 = torch.where(label==3,1,0)\n",
    "lab4 = torch.where(label==4,1,0);lab5 = torch.where(label==5,1,0)\n",
    "master_label = torch.stack([lab0,lab1,lab2,lab3,lab4,lab5], dim = 1)\n",
    "\n",
    "\n",
    "\n",
    "from matplotlib import cm\n",
    "\n",
    "#Visualizing tensor functions\n",
    "def write_video(file_path, frames, fps, grayscale=False):\n",
    "    \"\"\"\n",
    "    Writes frames to an mp4 video file\n",
    "    :param file_path: Path to output video, must end with .mp4\n",
    "    :param frames: List of PIL.Image objects\n",
    "    :param fps: Desired frame rate\n",
    "    \"\"\"\n",
    "    w, h = frames[0].size\n",
    "    fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "    writer = cv2.VideoWriter(file_path, fourcc, fps, (w, h))\n",
    "\n",
    "    for frame in frames:\n",
    "        open_cv_image = np.asarray(frame)\n",
    "        if not grayscale:\n",
    "            # Convert RGB to BGR \n",
    "            open_cv_image = open_cv_image[:, :, ::-1]\n",
    "           \n",
    "        else:\n",
    "            open_cv_image = cv2.cvtColor(open_cv_image, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        writer.write(open_cv_image)\n",
    "\n",
    "    writer.release() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "torch.Size([1, 1, 64, 512, 512]) torch.Size([1, 6, 64, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "sample = torch.reshape(sample, ( 1,1,sample.shape[3], sample.shape[1], sample.shape[2]))\n",
    "master_label = torch.reshape(master_label, (1, master_label.shape[1],master_label.shape[4], master_label.shape[2], master_label.shape[3]))\n",
    "print(master_label.shape[1])\n",
    "\n",
    "print( sample.shape, master_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 64, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "def sample_to_video(inputs, name=\"label_vid\", repeat=3):\n",
    "    inputs = inputs[0]\n",
    "    slices = []\n",
    "    for i in range(inputs.size()[2]):\n",
    "        new = inputs[:,:,i]\n",
    "        pil_image = transform(new)\n",
    "        # display(pil_image)\n",
    "        for _ in range(repeat):\n",
    "            slices.append(pil_image)\n",
    "        \n",
    "    return slices\n",
    "\n",
    "\n",
    "def label_to_video(inputs, name=\"label_vid\", repeat=3):\n",
    "    \"\"\"\n",
    "    Given an output tensor from the network with shape [6, 256, 256, 10]), return a\n",
    "    video of the tensor with name \"name\"\n",
    "    \"\"\"\n",
    "    num_classes=6\n",
    "    color = (torch.ones((1,inputs.shape[1],inputs.shape[2],inputs.shape[3]))/num_classes)\n",
    "    re_colored = inputs * color\n",
    "    re_colored = re_colored[0]\n",
    "    slices = []\n",
    "    magma = cm.get_cmap('YlGnBu')\n",
    "    for i in range(re_colored.size()[2]):\n",
    "        new = re_colored[:,:,i]\n",
    "        new = magma(new)\n",
    "        new = new[:,:,:3]*255\n",
    "        pil_image = PIL.Image.fromarray(new.astype(np.uint8))\n",
    "#         display(pil_image)\n",
    "        \n",
    "    return slices\n",
    "\n",
    "\n",
    "\n",
    "#sample\n",
    "img_size = (SLICE_LENGTH, 256, 256)\n",
    "\n",
    "\n",
    "# sample = torch.ones(1, 1, img_size[0], img_size[1], img_size[2])\n",
    "print(sample.size())\n",
    "slices=sample_to_video(sample)\n",
    "write_video(os.getcwd() + \"/m.mp4\", slices, 10, True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import codecs, json \n",
    "\n",
    "a = np.arange(10).reshape(2,5) # a 2 by 5 array\n",
    "b = a.tolist() # nested lists with same data, indices\n",
    "file_path = \"/path.json\" ## your path variable\n",
    "json.dump(b, codecs.open(file_path, 'w', encoding='utf-8'), \n",
    "          separators=(',', ':'), \n",
    "          sort_keys=True, \n",
    "          indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('new')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c39067fb85dad44b96a991ff273746e02ffde2a07ab0e300120c2298a074d00"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
