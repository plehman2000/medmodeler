{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd135d5b-76da-4d25-b7c5-a9d4815c62ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Patrick\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\detection\\anchor_utils.py:63: UserWarning: Failed to initialize NumPy: module compiled against API version 0x10 but this version of numpy is 0xf (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:77.)\n",
      "  device: torch.device = torch.device(\"cpu\"),\n"
     ]
    }
   ],
   "source": [
    "#RUNNING ON ENVIRONMENT 'UNEXT'\n",
    "# Config\n",
    "seed = 42  # for reproducibility\n",
    "training_split_ratio = 0.9  # use 90% of samples for training, 10% for testing\n",
    "num_epochs = 5\n",
    "# If the following values are False, the models will be downloaded and not computed\n",
    "compute_histograms = False\n",
    "train_whole_images = False \n",
    "train_patches = False\n",
    "import uuid\n",
    "from IPython.display import display\n",
    "import enum\n",
    "import time\n",
    "import random\n",
    "import multiprocessing\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import torchvision\n",
    "import torchio as tio\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "plt.rcParams['figure.figsize'] = 12, 6\n",
    "\n",
    "# import pytorch_lightning as pl\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchio\n",
    "# import pytorch_lightning as pl\n",
    "# import wandb\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67da409e-3a70-4097-b2a9-015216239fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "from matplotlib import cm\n",
    "import PIL\n",
    "import torchvision.transforms.functional as Ft\n",
    "import cv2\n",
    "\n",
    "transform = T.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5d9ae25-3b4a-4185-951f-5d1a84017a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_transforms = tio.Compose([tio.transforms.ToCanonical(),\n",
    "                   tio.RescaleIntensity((0, 1))])\n",
    "augment = tio.Compose([\n",
    "            tio.RandomAffine(),\n",
    "            tio.RandomMotion(p=0.1),\n",
    "            tio.RandomBiasField(p=0.25),\n",
    "        ])\n",
    "def sub_to_aug_pair(subject: tio.Subject):\n",
    "    \n",
    "    transformed_subject = base_transforms(subject)\n",
    "    augmented_subject = augment(transformed_subject)\n",
    "    \n",
    "    return transformed_subject, augmented_subject\n",
    "\n",
    "def tensor_to_disk(path_name, data):\n",
    "    with open(f'{path_name}.npy', 'wb') as f:\n",
    "        np.save(f, data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "930c05b2-bfb7-4274-8632-296cdd4225b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\Projects\\Lab\\MRI\\resave.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Projects/Lab/MRI/resave.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m SAVEPATH \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetcwd()\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Projects/Lab/MRI/resave.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m PATH \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetcwd()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Projects/Lab/MRI/resave.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m dataset_dir \u001b[39m=\u001b[39m Path(PATH \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mnormdata\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39m#switched from augfix due to one hot error\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Projects/Lab/MRI/resave.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m images_dir \u001b[39m=\u001b[39m dataset_dir \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mimages\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Projects/Lab/MRI/resave.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m labels_dir \u001b[39m=\u001b[39m dataset_dir \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "SAVEPATH = os.getcwd()\n",
    "PATH = os.getcwd()\n",
    "dataset_dir = Path(PATH + \"\\\\normdata\\\\\") #switched from augfix due to one hot error\n",
    "images_dir = dataset_dir / 'images'\n",
    "labels_dir = dataset_dir / 'labels'\n",
    "image_paths = sorted(images_dir.glob('*.nii.gz'))\n",
    "label_paths = sorted(labels_dir.glob('*.nii.gz'))\n",
    "assert len(image_paths) == len(label_paths)\n",
    "dataset = []\n",
    "count = 0\n",
    "for (image_path, label_path) in tqdm(zip(image_paths, label_paths), total=len(image_paths)):\n",
    "        norm = tio.Subject(\n",
    "            sample=tio.ScalarImage(image_path),\n",
    "            label =  tio.LabelMap(label_path))\n",
    "\n",
    "        tensor_to_disk(dataset_dir + f\"/labels_new/label{count}\", norm['label'][tio.DATA])        \n",
    "        tensor_to_disk(dataset_dir + f\"/images_new/sample{count}\", norm['sample'][tio.DATA])        \n",
    "        count +=1\n",
    "        del norm\n",
    "        break\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1d01ed-8092-456b-a215-8337d1ec20ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_to_new_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44964b1d-fdd2-4be1-bef6-b3e9a8267ab4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subject_list = mem_to_sub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d08dced-11cf-4529-9fcc-168a23fd506e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug, n = sub_to_aug_pair(subject_list[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3123c503-ac44-4292-a9dc-2c5c3df18406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3f1fcf-596e-4645-a3a4-d9ef3c6c14e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc04cbac-d401-47a8-8566-c0a9088c40de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#Visualizing tensor functions\n",
    "def write_video(file_path, frames, fps, grayscale=False):\n",
    "    \"\"\"\n",
    "    Writes frames to an mp4 video file\n",
    "    :param file_path: Path to output video, must end with .mp4\n",
    "    :param frames: List of PIL.Image objects\n",
    "    :param fps: Desired frame rate\n",
    "    \"\"\"\n",
    "    w, h = frames[0].size\n",
    "    fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "    writer = cv2.VideoWriter(file_path, fourcc, fps, (w, h))\n",
    "\n",
    "    for frame in frames:\n",
    "        open_cv_image = np.asarray(frame)\n",
    "        if not grayscale:\n",
    "            # Convert RGB to BGR \n",
    "            open_cv_image = open_cv_image[:, :, ::-1]\n",
    "           \n",
    "        else:\n",
    "            open_cv_image = cv2.cvtColor(open_cv_image, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        writer.write(open_cv_image)\n",
    "\n",
    "    writer.release() \n",
    "\n",
    "def sample_to_video(inputs, name=\"label_vid\", repeat=3):\n",
    "    inputs = inputs[0]\n",
    "    slices = []\n",
    "    for i in range(inputs.size()[2]):\n",
    "        new = inputs[:,:,i]\n",
    "        pil_image = transform(new)\n",
    "        for _ in range(repeat):\n",
    "            slices.append(pil_image)\n",
    "        \n",
    "    return slices\n",
    "\n",
    "\n",
    "def label_to_video(inputs, name=\"label_vid\", repeat=3):\n",
    "    \"\"\"\n",
    "    Given an output tensor from the network with shape [6, 256, 256, 10]), return a\n",
    "    video of the tensor with name \"name\"\n",
    "    \"\"\"\n",
    "    num_classes=6\n",
    "    color = (torch.ones((1,inputs.shape[1],inputs.shape[2],inputs.shape[3]))/num_classes)\n",
    "    re_colored = inputs * color\n",
    "    re_colored = re_colored[0]\n",
    "    slices = []\n",
    "    magma = cm.get_cmap('YlGnBu')\n",
    "    for i in range(re_colored.size()[2]):\n",
    "        new = re_colored[:,:,i]\n",
    "        new = magma(new)\n",
    "        new = new[:,:,:3]*255\n",
    "        pil_image = PIL.Image.fromarray(new.astype(np.uint8))\n",
    "#         display(pil_image)\n",
    "        for _ in range(repeat):\n",
    "            slices.append(pil_image)\n",
    "    return slices\n",
    "\n",
    "slices=label_to_video(tens['label'])\n",
    "write_video(os.getcwd() + \"/m.mp4\", slices, 10)\n",
    "\n",
    "slices=sample_to_video(d[0]['sample'])\n",
    "write_video(os.getcwd() + \"/test_sample_vid.mp4\", slices, 10, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b871563-d631-48ef-9a10-fbf696c3be50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0d34d4-ab4b-45be-a45e-5316708fafe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97da837c-f25b-4152-b9bf-7c0aa3a7af08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f2c4db-e805-4509-8cd2-2e303e6f9b32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e919e09-fb57-4811-bbc7-b665e1d4515c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36eb5c9-0419-4bb3-a1f0-ad639669184e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d4f626-72d0-4c05-84a9-be31f67641f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bad0c9d-563d-4c81-8b79-deb980eaf752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ffa89a-1a83-46b7-aa5f-406c50bfdfa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a217d6-981b-4528-b0fc-d22717335a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('new')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "5c39067fb85dad44b96a991ff273746e02ffde2a07ab0e300120c2298a074d00"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
